@inproceedings{07Zavaleta24,
author = {Angela Zavaleta Bernuy and Naaz Sibia and Pan Chen and Jessica Jia-Ni Xu and Elexandra Tran and Runlong Ye and Viktoria Pammer-Schindler and Andrew Petersen and Joseph Jay Williams and Michael Liut},
title = {Does the Medium Matter? An Exploration of Voice-Interaction for Self-Explanations},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661596},
doi = {10.1145/3643834.3661596},
abstract = {This research evaluates voice-based self-explanations as a pedagogical tool in preparation for lectures, assesses user preferences between voice and text, and derives design insights. We report two studies: Study 1, a quasi-experimental field study, with 247 participants divided into voice-based (N = 83), text-based (N = 81), and choice (N = 83) conditions. Study 2 uses semi-structured interviews (N = 16) to explore perceptions of the interaction paradigms in-depth. Results from the first study revealed a general preference for text, though voice users produced longer responses and more topic-related keywords. Over time, the preference for voice increased among students, from 10\% to 46\%, when given a choice. Study 2 suggested that factors like social presence contribute to hesitance toward voice-based explanations, with a cognitive load, self-confidence, and performance anxiety also influencing medium preferences. Our findings highlight design recommendations and demonstrate the potential of voice-based self-explanations in educational settings, indicating that mixed interfaces might better meet diverse needs.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {86–101},
numpages = {16},
keywords = {Active Learning, Explanation Prompts, Long-Term Memory, Self-Explanations, Student Performance, Text Explanations, Voice Explanations, Voice-based Interaction},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}

inproceedings{04Sibia24,
author = {Naaz Sibia and Angela Zavaleta Bernuy and Elexandra Tran and Jessica Jia-Ni Xu and Joseph Jay Williams and Andrew Petersen and Michael Liut},
title = {Exploring Self-Explanations in a Flipped Database Course},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664374},
doi = {10.1145/3663649.3664374},
abstract = {Self-explanations show promise for engaging students with preparatory materials, yet research into the types of self-explanations submitted in computing is limited. This paper examines student perceptions of self-explanation prompts in a flipped databases course, building on existing research that highlights the advantages of self-explanations in such contexts. We present our findings on students’ perceptions of the utility of self-explanation prompts and analyze
the nature of the explanations generated across distinct topics. The results suggest that self-explanations not only facilitate a deeper understanding of the subject matter but also promote the discovery of new connections and examples through rewording explanations. Furthermore, errors within self-explanations offer valuable insights for the early identification of misconceptions.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {20–26},
numpages = {7},
keywords = {Active Learning, Flipped Databases Course, Self-Explanations},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{12Zavaleta23,
author = {Barbara J. Ericson and Janice L. Pearce and Susan H. Rodger and Andrew Csizmadia and Rita Garcia and Francisco J. Gutierrez and Konstantinos Liaskos and Aadarsh Padiyath and Michael James Scott and David H. Smith and Jayakrishnan M. Warriem and Angela Zavaleta Bernuy},
title = {Multi-Institutional Multi-National Studies of Parsons Problems},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633498},
doi = {10.1145/3623762.3633498},
abstract = {Students are often asked to learn programming by writing code from scratch. However, many novices struggle to write code and get frustrated when their code does not work. Parsons problems can reduce the difficulty of a coding problem by providing mixed-up blocks the learner rearranges into the correct order. These mixed-up blocks can include distractor blocks that are not needed in a correct solution. Distractor blocks can include common errors, which may help students learn to recognize and fix such errors. Evidence suggests students find Parsons problems engaging, useful for learning to program, and typically easier and faster to solve than writing code from scratch, but with equivalent learning gains. Most research on Parsons problems prior to this work has been conducted at a single institution. This work addresses the need for replication across multiple contexts.A 2022 ITiCSE Parsons Problems Working Group conducted an extensive literature review of Parsons problems, designed several experimental studies for Parsons problems in Python, and created 'study-in-a-box' materials to help instructors run the experimental studies, but the 2022 working group had only sufficient time to pilot two of these studies.Our 2023 ITiCSE Parsons Problems Working Group reviewed these studies, revised some of the studies, expanded both the programming and natural languages used in some of the studies, created new studies, conducted think-aloud observations on some of the studies, and ran both revised as well as new experimental studies. The think-aloud observations and experimental studies provide evidence for using Parsons problems to help students learn common algorithms such as swap, and the usefulness of distractors in helping students learn to recognize, fix, and avoid common errors. In addition, our 2023 ITiCSE Parsons Problems Working Group reviewed Parsons problem papers published after the 2022 literature review and provided a literature review of multi-national (MIMN) studies conducted in computer science education to better understand the motivations and challenges in performing such MIMN studies.In summary, this article contributes an analysis of recent Parsons problem research papers, an itemization of considerations for MIMN studies, the results from our MIMN studies of Parsons problems, and a discussion of recent and future directions for MIMN studies of Parsons problems and more generally.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {57–107},
numpages = {51},
keywords = {parson's puzzles, multi-institutional study, parsons puzzles, parson's programming puzzles, multi-institutional multi-national study, parson's problems, parsons problems, multi-national study, code puzzles},
location = {<conf-loc>, <city>Turku</city>, <country>Finland</country>, </conf-loc>},
series = {ITiCSE-WGR '23}
}
