@inproceedings{11ly21,
author = {Anna Ly and Jack Parkinson and Quintin Cutts and Michael Liut and Andrew Petersen},
title = {Spatial Skills and Demographic Factors in CS1},
year = {2021},
isbn = {9781450384889},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488042.3488049},
doi = {10.1145/3488042.3488049},
abstract = {Motivation Prior studies have established that training spatial skills may improve outcomes in computing courses. Very few of these studies have, however, explored the impact of spatial skills training on women or examined its relationship with other factors commonly explored in the context of academic performance, such as socioeconomic background and self-efficacy. Objectives In this study, we report on a spatial skills intervention deployed in a computer programming course (CS1) in the first year of a post-secondary program. We explore the relationship between various demographic factors, course performance, and spatial skills ability at both the beginning and end of the term. Methods Data was collected using a combination of demographic surveys, existing self-efficacy and CS1 content instruments, and the Revised PVST:R spatial skills assessment. Spatial skills were evaluated both at the beginning of the term and at the end, after spatial skills training was provided. Results While little evidence was found to link spatial skills to socioeconomic status or self-efficacy, both gender identity and previous experience in computing were found to be correlated to spatial skills ability at the start of the course. Women initially recorded lower spatial skills ability, but after training, the distribution of spatial skills scores for women approached that of men. Discussion These findings suggest that, if offered early enough, spatial skills training may be able to remedy some differences in background that impact performance in computing courses. },
booktitle = {21st Koli Calling International Conference on Computing Education Research},
articleno = {4},
numpages = {10},
keywords = {retention, spatial skills, socioeconomic status, CS1, gender},
location = {Joensuu, Finland},
series = {Koli Calling '21}
}

@article{12parkinson21,
author = {Jack Parkinson and Ryan Bockmon and Quintin Cutts and Michael Liut and Andrew Petersen and Sheryl Sorby},
title = {Practice Report: Six Studies of Spatial Skills Training in Introductory Computer Science},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {2153-2184},
url = {https://doi.org/10.1145/3494574},
doi = {10.1145/3494574},
journal = {ACM Inroads},
month = {nov},
pages = {18–29},
numpages = {12}
}

@inproceedings{10ly2021revisiting,
  title={Revisiting Syntax Exercises in CS1},
  author={Anna Ly and John Edwards and Michael Liut and Andrew Petersen},
  booktitle={Proceedings of the 22st Annual Conference on Information Technology Education},
  pages={9--14},
  year={2021},
  url = {https://doi.org/10.1145/3450329.3476855},
  doi = {10.1145/3450329.3476855},
}

inproceedings{03Zhang21,
author = {Larry Yueli Zhang and Andrew K. Petersen and Michael Liut and Bogdan Simion and Furkan Alaca},
title = {A Multi-Course Report on the Experience of Unplanned Online Exams},
year = {2021},
isbn = {9781450380621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3408877.3432515},
doi = {10.1145/3408877.3432515},
abstract = {We report our experience of preparing and conducting unplanned online exams in the unique half-physical, half-virtual semester of Winter 2020. The report covers four courses in a large university's computer science program, ranging from first-year to third-year. With the data generated by students taking both in-person and online exams in multiple courses, we perform analyses to evaluate the validity of the online exams (especially the unproctored ones) as an assessment of student understanding. With the fine-grained student activity data provided by the online exam platform, we are also able to investigate the patterns in student exam-taking behaviours and their correlations with student performance on the exam. In addition, we share, in detail, the tips and lessons that were learned throughout the process of designing, implementing, and hosting the online exams.},
booktitle = {Proceedings of the 52nd ACM Technical Symposium on Computer Science Education},
pages = {17–23},
numpages = {7},
keywords = {student behaviour, online exams, assessment},
location = {Virtual Event, USA},
series = {SIGCSE '21}
}

@inproceedings{08Liut20,
 author = {Arnaud Deza and Haocheng Hu and Vaishvik Maisuria and Michael Liut and Andrew Petersen and Bogdan Simion},
 title = {Using Discussion Board Data to Hire Teaching Assistants},
 booktitle = {Proceedings of the 6th SPLICE Workshop at L@S},
 year = {2020},
 numpage = {6},
 url = {https://cssplice.github.io/LAS20/proc/SPLICE_2020_LS_paper_9.pdf},
}

@inproceedings{06Liut20,
author = {Simon and Oscar Karnalim and Judy Sheard and Ilir Dema and Amey Karkare and Juho Leinonen and Michael Liut and Ren\'{e}e McCauley},
title = {Choosing Code Segments to Exclude from Code Similarity Detection},
year = {2020},
isbn = {9781450382939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437800.3439201},
doi = {10.1145/3437800.3439201},
booktitle = {Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {1–19},
numpages = {19},
keywords = {collusion, academic integrity, plagiarism, code similarity detection},
location = {Trondheim, Norway},
series = {ITiCSE-WGR '20}
}
